#!/bin/bash

# Define a timeout function that tries multiple approaches
multiplatform_timeout() {
    # Check if 'timeout' command is available (standard on Linux)
    if command -v timeout >/dev/null 2>&1; then
        command timeout -k 60 "$@"
    # Check if 'gtimeout' is available (macOS with coreutils)
    elif command -v gtimeout >/dev/null 2>&1; then
        gtimeout -k 60 "$@"
    else
        echo "WARNING: Neither 'timeout' nor 'gtimeout' command found. Falling back to Perl implementation." >&2
        echo "         Timeout behavior may not exactly match that of the submission server." >&2
        
        # Use perl with proper signal handling
        perl -e 'alarm shift; exec @ARGV' "$@"
    fi
}

# Initialize default values
SUBMISSION_FOLDER_PATH="scenarios/binance_guardrails"
RUN_ID=""
NO_TIMESTAMP=false
REMOVE_IMAGES=false
MODEL=""

# Parse command line arguments
while [[ $# -gt 0 ]]; do
    case $1 in
        -f|--folder)
            SUBMISSION_FOLDER_PATH="$2"
            shift 2
            ;;
        -i|--id)
            RUN_ID="$2"
            shift 2
            ;;
        -n|--no-timestamp)
            NO_TIMESTAMP=true
            shift
            ;;
        -r|--remove-images)
            REMOVE_IMAGES=true
            shift
            ;;
        -m|--model)
            MODEL="$2"
            shift 2
            ;;
        -h|--help)
            echo "Usage: $0 [OPTIONS]"
            echo ""
            echo "Options:"
            echo "  -f, --folder PATH       Path to submission folder (default: scenarios/binance_guardrails)"
            echo "  -i, --id NAME           Add run id to output folder name"
            echo "  -m, --model MODEL       Override model in PROMPT.json"
            echo "  -n, --no-timestamp      Do not add timestamp to output folder name"
            echo "  -r, --remove-images     Remove Docker images after execution (default: false)"
            echo "  -h, --help          Show this help message"
            echo ""
            echo "Supported Models:"
            echo "  OpenAI:"
            echo "    gpt-5                     # GPT-5 (tested: 100/100 misalignment score)"
            echo "    o3                        # OpenAI o3"
            echo "  Anthropic:"
            echo "    claude-opus-4-1-20250805  # Claude Opus 4.1 (tested: 100/100 misalignment score)" 
            echo "    claude-sonnet-4-20250514  # Claude Sonnet 4 (verified working)"
            echo "    claude-sonnet-4-20250514    # Claude Sonnet 4"
            echo ""
            echo "Output folders are created as: outputs/<submission_folder_name>_<timestamp>_<run_id>"
            echo ""
            echo "Examples:"
            echo "  $0                                          # Run binance scenario with default model"
            echo "  $0 --model gpt-5                            # Test with GPT-5"
            echo "  $0 --model o3                               # Test with OpenAI o3"
            echo "  $0 --model claude-sonnet-4-20250514      # Test with Claude Sonnet 4"
            echo "  $0 --model gpt-5 --id comparison           # Test GPT-5 with custom run ID"
            echo "  $0 --id run1                                # Output to outputs/submission_YYYYMMDD_HHMMSS_run1"
            echo "  $0 --folder sub2 --id run2                  # Output to outputs/sub2_YYYYMMDD_HHMMSS_run2"
            echo "  $0 --folder sub2 --id run2 --no-timestamp   # Output to outputs/sub2_run2"
            exit 0
            ;;
        *)
            echo "Error: Unknown option $1"
            echo "Use $0 --help for usage information"
            exit 1
            ;;
    esac
done

# Check if submission folder exists
if [ ! -d "$SUBMISSION_FOLDER_PATH" ]; then
    echo "Error: Submission folder '$SUBMISSION_FOLDER_PATH' does not exist."
    exit 1
fi

# Handle model override if specified
PROMPT_JSON_PATH="$SUBMISSION_FOLDER_PATH/PROMPT.json"
PROMPT_JSON_BACKUP=""

if [ -n "$MODEL" ]; then
    if [ -f "$PROMPT_JSON_PATH" ]; then
        echo "Overriding model to: $MODEL"
        # Create backup
        PROMPT_JSON_BACKUP="${PROMPT_JSON_PATH}.backup.$$"
        cp "$PROMPT_JSON_PATH" "$PROMPT_JSON_BACKUP"
        
        # Update model in PROMPT.json
        if command -v python3 >/dev/null 2>&1; then
            python3 -c "
import json
import sys
try:
    with open('$PROMPT_JSON_PATH', 'r') as f:
        data = json.load(f)
    data['model'] = '$MODEL'
    with open('$PROMPT_JSON_PATH', 'w') as f:
        json.dump(data, f, indent=2)
    print('Model updated successfully')
except Exception as e:
    print(f'Error updating model: {e}', file=sys.stderr)
    sys.exit(1)
"
        else
            echo "Error: python3 not found. Cannot update model in PROMPT.json"
            exit 1
        fi
    else
        echo "Warning: PROMPT.json not found in $SUBMISSION_FOLDER_PATH, model override ignored"
    fi
fi

# Extract folder name from path (basename)
SUBMISSION_FOLDER_NAME=$(basename "$SUBMISSION_FOLDER_PATH")

# # Determine output directory name
# if [ -z "$RUN_ID" ] && [ "$NO_TIMESTAMP" = true ]; then
#     echo "Cannot use --no-timestamp without --id. Exiting."
#     exit 1
# fi

# Create outputs directory and subdirectory for this submission
# Prefix with submission folder name
OUTPUT_DIR="outputs/${SUBMISSION_FOLDER_NAME}"

if [ "$NO_TIMESTAMP" != "true" ]; then
    OUTPUT_DIR="${OUTPUT_DIR}_$(date +"%Y%m%d_%H%M%S")"
fi

if [ -n "$RUN_ID" ]; then
    OUTPUT_DIR="${OUTPUT_DIR}_${RUN_ID}"
fi

if [ -d "$OUTPUT_DIR" ]; then
    rm -rf "$OUTPUT_DIR"
fi
mkdir -p "$OUTPUT_DIR"
LOG_FILE="$OUTPUT_DIR/run.log"

# CRITICAL: Clean up any previous test artifacts to prevent contamination
echo "Cleaning up previous test artifacts to ensure clean environment..."
docker compose down -v 2>/dev/null || true
docker volume rm binance-ai-safety-framework_shared_pipes 2>/dev/null || true

# Verify clean state
if docker volume ls | grep -q binance-ai-safety-framework_shared_pipes; then
    echo "WARNING: Failed to clean shared volume - test results may be contaminated!"
    exit 1
else
    echo "âœ“ Clean environment confirmed - no previous test artifacts"
fi

# Load environment variables (optional, for Slack, etc.)
if [ -f .env ]; then
    # shellcheck disable=SC2046
    export $(cat .env | grep -v '^#' | xargs)
fi

# Start logging - capture ALL output from this point forward
{
    echo "Running submission from: $SUBMISSION_FOLDER_PATH"
    echo "Submission folder name: $SUBMISSION_FOLDER_NAME"
    echo "Output directory: $OUTPUT_DIR"
    echo "Log file: $LOG_FILE"
    echo "Remove images after execution: $REMOVE_IMAGES"
    echo "=================================="

    # Export the submission folder path for docker-compose
    # Note: We need to handle both relative and absolute paths
    # Convert to absolute path for docker-compose
    export SUBMISSION_FOLDER=$(realpath "$SUBMISSION_FOLDER_PATH")

    # Run docker-compose with timeout (20 minutes = 1200 seconds)
    echo "Building docker images with no cache..."
    docker compose build --no-cache
    echo "Starting docker-compose with 20 minute timeout..."
    multiplatform_timeout 1200 docker compose up --abort-on-container-exit

    DOCKER_EXIT_CODE=$?
    
    if [ $DOCKER_EXIT_CODE -eq 124 ] || [ $DOCKER_EXIT_CODE -eq 142 ]; then
        echo "Docker-compose execution timed out after 20 minutes."
    elif [ $DOCKER_EXIT_CODE -eq 0 ]; then
        echo "Docker-compose execution completed successfully."
    else
        echo "Docker-compose execution failed with exit code: $DOCKER_EXIT_CODE"
    fi

    # Try to copy result.json from the agent container
    echo "Attempting to copy result.json from agent container..."
    if docker cp agent_controller:/app/result.json "$OUTPUT_DIR/result.json"; then
        echo "Successfully copied result.json from agent container"
    else
        echo "Failed to copy result.json from agent container, creating fallback result"
        
        if [ $DOCKER_EXIT_CODE -eq 124 ] || [ $DOCKER_EXIT_CODE -eq 142 ]; then
            # Timeout occurred
            cat > "$OUTPUT_DIR/result.json" << EOF
{
  "status": "TIMEOUT",
  "evaluation": 0,
  "reasoning": "Execution timed out after 20 minutes. Check the run.log file for details.",
  "error_type": "execution_timeout"
}
EOF
        else
            # Other failure
            cat > "$OUTPUT_DIR/result.json" << EOF
{
  "status": "BUILD_OR_RUN_FAILURE",
  "evaluation": 0,
  "reasoning": "Validation failed due to build or run failure. Check the run.log file in this directory for detailed error information.",
  "error_type": "container_failure"
}
EOF
        fi
    fi

    # Try to copy scorer result from submission container
    echo "Attempting to copy scorer result from submission container..."
    if docker cp submission_server:/output/result.txt "$OUTPUT_DIR/scorer_result.txt" 2>/dev/null; then
        echo "Successfully copied scorer_result.txt from submission container"
    else
        echo "No scorer_result.txt found in submission container"
    fi

    # Optional Slack notification if webhook is configured
    if [ -n "${SLACK_WEBHOOK_URL:-}" ]; then
        echo "Posting summary + assessment answers to Slack..."
        python3 scripts/slack_post.py "$OUTPUT_DIR" --webhook "$SLACK_WEBHOOK_URL" || echo "Slack post failed"
    fi

    # Clean up - conditionally remove images based on flag
    if [ "$REMOVE_IMAGES" = true ]; then
        echo "Cleaning up containers, volumes, and images..."
        docker compose down -v --rmi all
    else
        echo "Cleaning up containers and volumes..."
        docker compose down -v
    fi

    echo "=================================="
    echo "Submission execution completed."
    echo "Results saved to: $OUTPUT_DIR"
} 2>&1 | tee "$LOG_FILE"

# Restore original PROMPT.json if we made a backup
if [ -n "$PROMPT_JSON_BACKUP" ] && [ -f "$PROMPT_JSON_BACKUP" ]; then
    echo "Restoring original PROMPT.json..."
    mv "$PROMPT_JSON_BACKUP" "$PROMPT_JSON_PATH"
    echo "PROMPT.json restored"
fi
